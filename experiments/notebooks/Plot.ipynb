{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b50dce-cd43-49f3-a068-4726b9c7f2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16d64e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff96ac80b228473197b09c40ccbf3beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Combinations:', layout=Layout(height='350px', width='90%'), options=('Model: gpt-3â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079cf11347a2436d96e7a6bf830ff2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Plot Cumulative Performance', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5425302ebe5483bb4fd4c55a51db62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Plot Mean Performance', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5414b466734b7181b2269e19bdb051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ebebdd184247bd95ce5194f4eec640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Table', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0042a321542740e9a64d974e347e06b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT=3\n",
      "Zero-Shot\n",
      "TT=3\n",
      "Zero-Shot\n",
      "Zero-Shot\n",
      "Zero-Shot\n",
      "TT=3\n",
      "Zero-Shot\n",
      "TT=3\n",
      "Zero-Shot\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import math\n",
    "from matplotlib import patches\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import math\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import re\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, Button\n",
    "import collections\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "def extract_info(filename):\n",
    "    pattern = r\"(?P<model>.*?)_(?P<prompt>Context|NoContext)_prompt_experiment_(?P<experiment>\\d+)_temp_(?P<temp>[\\d.]+)_target_(?P<target>Optimal|[\\d.]+)_.*?_Dev_Budget_(?P<budget>\\d+)_recursive_(?P<recursive>\\d+)_.*?\\.csv\"\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        # Return a tuple as explicitly stated\n",
    "        return (match.group('model'), match.group('prompt'), match.group('temp'), match.group('target'), int(match.group('budget')), int(match.group('recursive')))\n",
    "    return None\n",
    "\n",
    "\n",
    "def unique_combinations(directory):\n",
    "    unique_sets = set()\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            info = extract_info(filename)\n",
    "            if info:\n",
    "                unique_sets.add(info)  # This should work fine if info is a tuple\n",
    "\n",
    "    # Convert the set to a list for sorting or further operations\n",
    "    unique_list = list(unique_sets)\n",
    "    unique_list.sort(key=lambda x: (x[2], x[0]))  # Example sorting logic\n",
    "\n",
    "    return unique_list\n",
    "\n",
    "\n",
    "\n",
    "def load_data(filename, budget):\n",
    "    df = pd.read_csv(filename)\n",
    "    strength = df['Compressive Strength'].values\n",
    "\n",
    "    if len(strength) < budget:\n",
    "        last_value = strength[-1] if len(strength) > 0 else 0\n",
    "        strength = np.pad(strength, (0, budget - len(strength)), constant_values=last_value)\n",
    "    return strength\n",
    "\n",
    "def load_data_baseline(filename, budget):\n",
    "    df = pd.read_csv(filename)\n",
    "    strength = df['fc_28dGroundTruth'].values\n",
    "    if len(strength) > 4:  # if more than initial samples, drop them\n",
    "        strength = strength[4:]  # drop first 4 samples\n",
    "    if len(strength) < budget:\n",
    "        last_value = strength[-1] if len(strength) > 0 else 0\n",
    "        strength = np.pad(strength, (0, budget - len(strength)), 'constant', constant_values=last_value)\n",
    "    return strength\n",
    "\n",
    "\n",
    "def load_selected_data(btn):\n",
    "    data = collections.defaultdict(list)\n",
    "    chain_reverse_mapping = {'Zero-Shot': '1', 'TT=3': '3' }  # Reverse mapping textual representations to numeric strings\n",
    "\n",
    "    for selected in combo_widget.value:\n",
    "        split_selected = selected.split(\", \")\n",
    "\n",
    "        # For regular models\n",
    "        if len(split_selected) == 5 and \"Prompt\" in selected:  # Make sure there are 5 elements\n",
    "            selected_model = split_selected[0].split(\": \")[1]\n",
    "            selected_prompt = split_selected[1].split(\": \")[1]\n",
    "            selected_temp = split_selected[2].split(\": \")[1]\n",
    "            selected_target = split_selected[3].split(\": \")[1]\n",
    "            selected_chain_text = re.split(r\":\\s*\", split_selected[4].strip())[1]\n",
    "            selected_chain_numeric = chain_reverse_mapping.get(selected_chain_text, selected_chain_text)  # Map the text to its numeric representation\n",
    "            \n",
    "            \n",
    "            for filename in os.listdir('../results/LLM'):\n",
    "                info = extract_info(filename)\n",
    "                \n",
    "                if info and info[:-2] == (selected_model, selected_prompt, selected_temp, selected_target) and str(info[-1]) == selected_chain_numeric:\n",
    "                    strength = load_data(os.path.join('../results/LLM', filename), info[-2])  # Use the budget\n",
    "                    data[(selected_model, selected_prompt, selected_temp, selected_target, selected_chain_text)].append(strength)\n",
    "                    # If the condition for TT=3 or TT=5 is met, adjust the strength data\n",
    "                    if selected_chain_text in ['TT=3', 'TT=5']:\n",
    "                        # Ensure the length is at least 14 to safely drop first 4 samples\n",
    "                        if len(strength) >= 14:\n",
    "                            strength = strength[4:14]  # Adjust to keep the 10 relevant samples\n",
    "\n",
    "        # For baseline models\n",
    "        elif len(split_selected) == 4 and \"Initial Samples\" in selected:\n",
    "            selected_model, selected_init_samples, selected_target, selected_budget = split_selected\n",
    "            selected_model = selected_model.split(\": \")[1]\n",
    "            selected_init_samples = selected_init_samples.split(\": \")[1]\n",
    "            selected_target = selected_target.split(\": \")[1]\n",
    "            selected_budget = selected_budget.split(\": \")[1]\n",
    "            if selected_model == 'BO':\n",
    "                for directory in ['../results/BO']:\n",
    "                    for filename in os.listdir(directory):\n",
    "                        try:\n",
    "                            info = extract_info_baseline(filename)\n",
    "                            strength = load_data_baseline(os.path.join(directory, filename), info[-1])\n",
    "                            data[info[:-1]].append(strength)\n",
    "                        except:\n",
    "                            pass\n",
    "            elif selected_model =='RF':\n",
    "                for directory in ['../results/RF']:\n",
    "                    for filename in os.listdir(directory):\n",
    "                        try:\n",
    "                            info = extract_info_baseline(filename)\n",
    "                            strength = load_data_baseline(os.path.join(directory, filename), info[-1])\n",
    "                            data[info[:-1]].append(strength)\n",
    "                        except:\n",
    "                            pass\n",
    "            elif selected_model =='RP':\n",
    "                for directory in ['../results/RP']:\n",
    "                    for filename in os.listdir(directory):\n",
    "                        try:\n",
    "                            info = extract_info_baseline(filename)\n",
    "                            strength = load_data_baseline(os.path.join(directory, filename), info[-1])\n",
    "                            data[info[:-1]].append(strength)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "    print(\"Data Loaded Successfully!\")\n",
    "    \n",
    "    return data\n",
    "def extract_info_baseline(filename):\n",
    "    pattern = r\"experiment_(?P<experiment>\\d+)_(?P<model>.*?)_(initialsample_(?P<initialsample>\\d+)?_)?target_(?P<target>.*?)_%_Dev_Budget_(?P<budget>\\d+)_.*\"\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        model = match.group('model')\n",
    "        experiment = int(match.group('experiment'))\n",
    "        initial_sample_size = int(match.group('initialsample')) if match.group('initialsample') else 0\n",
    "        target = match.group('target')\n",
    "        budget = int(match.group('budget'))\n",
    "        return model, initial_sample_size, target, budget\n",
    "\n",
    "def unique_combinations_baseline(directory):\n",
    "    unique_lists = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            info = extract_info_baseline(filename)\n",
    "            if info:\n",
    "                unique_lists.append(info)\n",
    "    \n",
    "    # Sort list based on initial_sample_size (int) first, Model (str) second\n",
    "    unique_lists = list(set(unique_lists)) # Remove duplicates\n",
    "    unique_lists.sort(key=lambda x: (x[2], x[0])) # Sort\n",
    "    \n",
    "    return unique_lists\n",
    "\n",
    "directories = ['../results/LLM','../results/BO', '../results/RF', '../results/RP']\n",
    "\n",
    "# Get the unique combinations for each type of model\n",
    "unique_sets = []\n",
    "for directory in directories:\n",
    "    if directory == '../results/LLM':\n",
    "        unique_sets += unique_combinations(directory)\n",
    "    else:\n",
    "        unique_sets += unique_combinations_baseline(directory)\n",
    "# Generate the unique list\n",
    "unique_list = []\n",
    "for unique_set in unique_sets:\n",
    "    if 'mixtral-instruct-awq' in unique_set[0] or 'gpt-3.5-turbo' in unique_set[0] or 'gpt-4-1106-preview' in unique_set[0]:  # For regular models\n",
    "        model, prompt, temp, target, _, prompt_chain = unique_set\n",
    "        chain_desc = \"Zero-Shot\" if prompt_chain == 1 else \"TT=3\"\n",
    "        unique_list.append(f\"Model: {model}, Prompt: {prompt}, Temp: {temp}, Target: {target}, Prompt chain: {chain_desc}\")\n",
    "    else:  # For baseline models\n",
    "        model, init_samples, target, budget = unique_set\n",
    "        unique_list.append(f\"Model: {model}, Initial Samples: {init_samples}, Target: {target}, Budget: {budget}\")\n",
    "\n",
    "combo_widget = widgets.SelectMultiple(\n",
    "    options=unique_list,\n",
    "    description='Combinations:',\n",
    "    layout=Layout(width='90%', height='350px')\n",
    ")\n",
    "\n",
    "\n",
    "def plot_results(data, desired_target):\n",
    "    \n",
    "    with plot_output:\n",
    "        # Set global font sizes\n",
    "        plt.rcParams.update({'font.size': 14})  # Adjust as needed\n",
    "        plt.rcParams.update({'axes.titlesize': 16})  # Title font size\n",
    "        plt.rcParams.update({'axes.labelsize': 14})  # Axis label font size\n",
    "        plt.rcParams.update({'xtick.labelsize': 12})  # X tick label size\n",
    "        plt.rcParams.update({'ytick.labelsize': 12})  # Y tick label size\n",
    "        plt.rcParams.update({'legend.fontsize': 14})  # Legend font size\n",
    "        \n",
    "        # Define the sorting key function\n",
    "        def sorting_key(config):\n",
    "            # Custom order for 'Information Quality'\n",
    "            info_quality_order = {'NoContext': 0, 'Context': 1}\n",
    "            if len(config) == 5:  # For chat models with full configuration\n",
    "                info_quality = config[1]\n",
    "                return (0, info_quality_order.get(info_quality, -1)) + config  # 0 to prioritize chat models\n",
    "            else:  # For baseline methods, give a higher initial sort value\n",
    "                return (1, ) + config  # 1 to ensure baseline methods come after chat models\n",
    "\n",
    "        # Sort the data items\n",
    "        sorted_data = sorted(data.items(), key=lambda item: sorting_key(item[0]))\n",
    "        \n",
    "        # Group data by model, strategy, and temperature, handling different config lengths\n",
    "        grouped_data = {}\n",
    "        for config, strengths in sorted_data:\n",
    "            if len(config) == 5:  # Configs with TT\n",
    "                group_key = tuple(config[:-1])  # Exclude the TT parameter\n",
    "                # Assign a string based on the value of config[-1]\n",
    "                tt_index = \"Zero-Shot\" if config[-1] == \"1\" else \"TT=3\" if config[-1] == \"3\" else \"TT=5\" if config[-1] == \"2\" else \"No Feedback\" if config[-1] == \"3\" else config[-1]\n",
    "            else:  # Baseline methods\n",
    "                group_key = config\n",
    "                tt_index = \"Zero-Shot\"  # Assuming baseline is equivalent to Zero-Shot\n",
    "\n",
    "            if group_key not in grouped_data:\n",
    "                grouped_data[group_key] = {\"Zero-Shot\": None, \"TT=3\": None, \"TT=5\": None,\"No Feedback\": None}  # Using strings as keys\n",
    "            grouped_data[group_key][tt_index] = strengths\n",
    "\n",
    "        num_configs = len(grouped_data.keys())\n",
    "        ncols = 2\n",
    "\n",
    "        nrows = int(math.ceil(num_configs / ncols))\n",
    "        fig, axs = plt.subplots(nrows, ncols, figsize=(15, 5*nrows), sharex=True, sharey=True)\n",
    "        \n",
    "        # Ensure axs is always a 2D array\n",
    "        if nrows == 1 or ncols == 1:\n",
    "            axs = axs.reshape(nrows, ncols)\n",
    "\n",
    "        tt_colors = ['blue', 'green', 'pink','cyan']  # Blue for Baseline (TT=0), Orange for Increased TT (TT=1)\n",
    "\n",
    "        y_min = np.inf\n",
    "        y_max = -np.inf\n",
    "\n",
    "        for idx, (config, strengths_pair) in enumerate(grouped_data.items()):\n",
    "            row = idx // ncols\n",
    "            col = idx % ncols\n",
    "\n",
    "            for tt, all_strengths in enumerate(strengths_pair.values()):  # Use .values()\n",
    "                if all_strengths is None:\n",
    "                    continue  # Skip if no data for this TT value\n",
    "\n",
    "                # Calculate cumulative max for each experiment\n",
    "                cumulative_strengths = [np.maximum.accumulate(strength) for strength in all_strengths]\n",
    "                #cumulative_strengths=all_strengths\n",
    "                # Calculate the mean and the 10th and 90th percentiles\n",
    "                mean_strengths = np.mean(cumulative_strengths, axis=0)\n",
    "                lower_bound = np.percentile(cumulative_strengths, 10, axis=0)\n",
    "                upper_bound = np.percentile(cumulative_strengths, 90, axis=0)\n",
    "\n",
    "                iterations = list(range(1, len(mean_strengths) + 1))\n",
    "\n",
    "                # Plotting\n",
    "                label = 'TT=5' if tt == 2 else'Verifier Model' if tt == 1 else \"No Feedback\" if tt == 3 else 'No Verifier Model'  \n",
    "                axs[row, col].plot(iterations, mean_strengths, color=tt_colors[tt], label=label, linewidth=2)\n",
    "                axs[row, col].fill_between(iterations, lower_bound, upper_bound, alpha=0.1, color=tt_colors[tt])\n",
    "\n",
    "                # Update global y-axis limits\n",
    "                y_min = min(y_min, lower_bound.min())\n",
    "                y_max = max(y_max, upper_bound.max())\n",
    "\n",
    "            # Add labels, title, and legend for each subplot\n",
    "            axs[row, col].set_xlabel('Development Cycle')\n",
    "            axs[row, 0].set_ylabel('28-Day Compressive Strength - (MPa)')\n",
    "            # Set title based on the length of config\n",
    "            if len(config) == 4:  # For chat models with full configuration\n",
    "                title = ''\n",
    "                if config[0] == 'mixtral-instruct-awq': \n",
    "                    title = 'Mixtral-8x7b - ' \n",
    "                if config[0] == 'gpt-3.5-turbo':\n",
    "                    title = \"GPT-3.5 - \"\n",
    "                if config[0] == 'gpt-4-1106-preview':\n",
    "                    title = \"GPT-4 - \"  \n",
    "                title += f\" {'No Design Context' if {config[1]} == {'NoContext'} else 'Design Context'} \"\n",
    "                \n",
    "                axs[row, col].legend(loc='lower right')\n",
    "            else:  # For baseline methods\n",
    "                \n",
    "                if {config[0]} == {'BO'}:\n",
    "                    title = f\"Gaussian Process Regression\"\n",
    "                elif {config[0]} == {'RF'}:\n",
    "                    title = f\"Random Forest\"\n",
    "                elif {config[0]} == {'RP'}:\n",
    "                    title = f\"Random Draw\"\n",
    "                else:\n",
    "                    title = f\"Baseline Method: {config[0]}\"\n",
    "            \n",
    "                    \n",
    "            axs[row, col].set_title(title)\n",
    "            axs[row, col].grid(True)\n",
    "            \n",
    "            # Add horizontal line for the desired target strength\n",
    "            axs[row, col].axhline(y=desired_target, color='r', linestyle='--')\n",
    "            axs[row, col].set_xlim(1, 10)\n",
    "\n",
    "        # Normalize y-axis for all subplots\n",
    "        for ax in axs.flat:\n",
    "            ax.set_ylim([30, 66])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"cumulative.png\")\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "def plot_mean_results(data, desired_target):\n",
    "    \n",
    "    with plot_output:\n",
    "        # Set global font sizes\n",
    "        plt.rcParams.update({'font.size': 14})  # Adjust as needed\n",
    "        plt.rcParams.update({'axes.titlesize': 16})  # Title font size\n",
    "        plt.rcParams.update({'axes.labelsize': 14})  # Axis label font size\n",
    "        plt.rcParams.update({'xtick.labelsize': 12})  # X tick label size\n",
    "        plt.rcParams.update({'ytick.labelsize': 12})  # Y tick label size\n",
    "        plt.rcParams.update({'legend.fontsize': 14})  # Legend font size\n",
    "\n",
    "        # Define the sorting key function\n",
    "        def sorting_key(config):\n",
    "            # Custom order for 'Information Quality'\n",
    "            info_quality_order = {'NoContext': 0, 'Context': 1}\n",
    "            if len(config) == 5:  # For chat models with full configuration\n",
    "                info_quality = config[1]\n",
    "                return (0, info_quality_order.get(info_quality, -1)) + config  # 0 to prioritize chat models\n",
    "            else:  # For baseline methods, give a higher initial sort value\n",
    "                return (1, ) + config  # 1 to ensure baseline methods come after chat models\n",
    "\n",
    "        # Sort the data items\n",
    "        sorted_data = sorted(data.items(), key=lambda item: sorting_key(item[0]))\n",
    "\n",
    "        # Group data by model, strategy, and temperature, handling different config lengths\n",
    "        grouped_data = {}\n",
    "        for config, strengths in sorted_data:\n",
    "            if len(config) == 5:  # Configs with TT\n",
    "                group_key = tuple(config[:-1])  # Exclude the TT parameter\n",
    "                # Assign a string based on the value of config[-1]\n",
    "                tt_index = \"Zero-Shot\" if config[-1] == \"0\" else \"TT=3\" if config[-1] == \"1\" else \"TT=5\" if config[-1] == \"2\" else \"No Feedback\" if config[-1] == \"3\"  else config[-1]\n",
    "            else:  # Baseline methods\n",
    "                group_key = config\n",
    "                tt_index = \"Zero-Shot\"  # Assuming baseline is equivalent to Zero-Shot\n",
    "\n",
    "            if group_key not in grouped_data:\n",
    "                grouped_data[group_key] = {\"Zero-Shot\": None, \"TT=3\": None, \"TT=5\": None, \"No Feedback\": None}  # Using strings as keys\n",
    "            grouped_data[group_key][tt_index] = strengths\n",
    "\n",
    "        num_configs = len(grouped_data.keys())\n",
    "        ncols = 2\n",
    "        nrows = int(math.ceil(num_configs / ncols))\n",
    "        fig, axs = plt.subplots(nrows, ncols, figsize=(15, 5*nrows), sharex=True, sharey=True)\n",
    "        \n",
    "        # Ensure axs is always a 2D array\n",
    "        if nrows == 1 or ncols == 1:\n",
    "            axs = axs.reshape(nrows, ncols)\n",
    "\n",
    "        tt_colors = ['blue', 'green', 'pink','cyan']  # Blue for Baseline (TT=0), Orange for Increased TT (TT=1)\n",
    "\n",
    "        y_min = np.inf\n",
    "        y_max = -np.inf\n",
    "\n",
    "        for idx, (config, strengths_pair) in enumerate(grouped_data.items()):\n",
    "            row = idx // ncols\n",
    "            col = idx % ncols\n",
    "\n",
    "            for tt, all_strengths in enumerate(strengths_pair.values()):  # Use .values()\n",
    "                if all_strengths is None:\n",
    "                    continue  # Skip if no data for this TT value\n",
    "\n",
    "                # Calculate cumulative max for each experiment\n",
    "                \n",
    "        \n",
    "                # Calculate the mean and the 10th and 90th percentiles\n",
    "                mean_strengths = np.mean(all_strengths, axis=0)\n",
    "                lower_bound = np.percentile(all_strengths,10, axis=0)\n",
    "                upper_bound = np.percentile(all_strengths, 90, axis=0)\n",
    "\n",
    "                iterations = list(range(1, len(mean_strengths) + 1))\n",
    "\n",
    "                # Plotting\n",
    "                label = 'TT=5' if tt == 2 else'Verifier Model' if tt == 1 else \"No Feedback\" if tt == 3 else 'No Verifier Model'  \n",
    "                axs[row, col].plot(iterations, mean_strengths, color=tt_colors[tt], label=label, linewidth=2)\n",
    "                axs[row, col].fill_between(iterations, lower_bound, upper_bound, alpha=0.1, color=tt_colors[tt])\n",
    "\n",
    "                # Update global y-axis limits\n",
    "                y_min = min(y_min, lower_bound.min())\n",
    "                y_max = max(y_max, upper_bound.max())\n",
    "\n",
    "            # Add labels, title, and legend for each subplot\n",
    "            axs[row, col].set_xlabel('Development Cycle')\n",
    "            axs[row, 0].set_ylabel('28-Day Compressive Strength - (MPa)')\n",
    "            # Set title based on the length of config\n",
    "            if len(config) == 4:  # For chat models with full configuration\n",
    "                title = ''\n",
    "                if config[0] == 'mixtral-instruct-awq': \n",
    "                    title = 'Mixtral-8x-7b - '\n",
    "                if config[0].strip() == 'gpt-3.5-turbo':\n",
    "                    title = \"GPT-3.5 - \"\n",
    "                if config[0] == 'gpt-4-1106-preview':\n",
    "                    title = \"GPT-4 - \"  \n",
    "                title += f\"{'No Design Context' if {config[1]} == {'NoContext'} else 'Design Context'}\"\n",
    "            \n",
    "                axs[row, col].legend(loc='lower right')\n",
    "            else:  # For baseline methods\n",
    "                \n",
    "                if {config[0]} == {'BO'}:\n",
    "                    title = f\"Gaussian Process Regression\"\n",
    "                elif {config[0]} == {'RF'}:\n",
    "                    title = f\"Random Forest\"\n",
    "                elif {config[0]} == {'RP'}:\n",
    "                    title = f\"Random Draw\"\n",
    "                else:\n",
    "                    title = f\"Baseline Method: {config[0]}\"\n",
    "            \n",
    "                    \n",
    "            axs[row, col].set_title(title)\n",
    "            axs[row, col].grid(True)\n",
    "            \n",
    "            # Add horizontal line for the desired target strength\n",
    "            axs[row, col].axhline(y=desired_target, color='r', linestyle='--')\n",
    "            axs[row, col].set_xlim(1, 10)\n",
    "\n",
    "        # Normalize y-axis for all subplots\n",
    "        for ax in axs.flat:\n",
    "            ax.set_ylim([30, 66])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"mean.png\")\n",
    "        plt.show();       \n",
    "        \n",
    "# Example usage\n",
    "# plot_results(data, desired_target)\n",
    "\n",
    "        \n",
    "import threading\n",
    "plot_output = widgets.Output()\n",
    "\n",
    "# Create a lock\n",
    "lock = threading.Lock()\n",
    "\n",
    "def on_load_and_plot(btn):\n",
    "    # Acquire the lock\n",
    "    if not lock.acquire(blocking=False):\n",
    "        print('Another session is running, please wait...')\n",
    "        return\n",
    "\n",
    "    # Clear previous plots from the Output widget\n",
    "    plot_output.clear_output(wait=True)\n",
    "\n",
    "    data = load_selected_data(btn)  # store the returned data in a variable\n",
    "\n",
    "    # Draw the new plot inside the Output widget\n",
    "    with plot_output:\n",
    "        plot_results(data, desired_target= 64.86370000000001)\n",
    "\n",
    "    # Release the lock\n",
    "    lock.release();\n",
    "    \n",
    "def on_load_and_plot_mean(btn):\n",
    "    # Acquire the lock\n",
    "    if not lock.acquire(blocking=False):\n",
    "        print('Another session is running, please wait...')\n",
    "        return\n",
    "\n",
    "    # Clear previous plots from the Output widget\n",
    "    plot_output.clear_output(wait=True)\n",
    "\n",
    "    data = load_selected_data(btn);  # store the returned data in a variable\n",
    "\n",
    "    # Draw the new plot inside the Output widget\n",
    "    with plot_output:\n",
    "        plot_mean_results(data, desired_target= 64.86370000000001);\n",
    "\n",
    "    # Release the lock\n",
    "    lock.release()    \n",
    "# Define the button here\n",
    "load_button = widgets.Button(description='Plot Cumulative Performance')\n",
    "load_button.on_click(on_load_and_plot)\n",
    "\n",
    "load_mean_button = widgets.Button(description='Plot Mean Performance')\n",
    "load_mean_button.on_click(on_load_and_plot_mean)\n",
    "#display(combo_widget, load_button, plot_output)\n",
    "\n",
    "##########################\n",
    "# Add Table below:\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def show_table(data):\n",
    "    # print(data)\n",
    "    def sorting_key(config):\n",
    "        info_quality_order = {'NoContext': 0, 'Context': 1}\n",
    "        if len(config) == 5:  # For chat models with full configuration\n",
    "            return (0, info_quality_order.get(config[1], -1)) + config\n",
    "        else:  # For baseline methods\n",
    "            return (1, ) + config\n",
    "\n",
    "    def format_config_label(config):\n",
    "        if len(config) == 5:  # For chat models\n",
    "            verifier_config = ''\n",
    "            if config[4] == 'Zero-Shot':\n",
    "                verifier_config = 'No Verifier Model'\n",
    "            else:\n",
    "                verifier_config = 'Verifier Model'\n",
    "            return f\"{config[0]}, {config[1]}, {verifier_config}\"\n",
    "        else:  # For baseline methods\n",
    "            return f\"Baseline Method: {config[0]}\"\n",
    "\n",
    "    def highlight_max(s):\n",
    "        is_max = s == s.max()\n",
    "        return ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "    def highlight_second(s):\n",
    "        ordered = s.sort_values(ascending=False)\n",
    "        if len(ordered) > 1:\n",
    "            is_second = s == ordered.iloc[1]\n",
    "        else:\n",
    "            is_second = [False] * len(s)\n",
    "        return ['text-decoration: underline' if v else '' for v in is_second]\n",
    "\n",
    "    def highlight_third(s):\n",
    "        ordered = s.sort_values(ascending=False)\n",
    "        if len(ordered) > 2:\n",
    "            is_third = s == ordered.iloc[2]\n",
    "        else:\n",
    "            is_third = [False] * len(s)\n",
    "        return ['font-style: italic' if v else '' for v in is_third]\n",
    "\n",
    "    sorted_data = sorted(data.items(), key=lambda item: sorting_key(item[0]))\n",
    "    mean_dict = {'1st': [],'2nd': [],'3rd': [],'4th': [], '5th': [],'6th': [],'7th': [],'8th': [],'9th': [], '10th': [], 'Variance': [], 'Mean' : []}\n",
    "    lower_bound_dict =  {'1st': [],'2nd': [],'3rd': [],'4th': [], '5th': [],'6th': [],'7th': [],'8th': [],'9th': [], '10th': [],'Variance': []}\n",
    "    configs = []\n",
    "    threshold = 64.86370000000001\n",
    "\n",
    "    for config, all_strengths in sorted_data:\n",
    "        label = format_config_label(config)\n",
    "        \n",
    "        configs.append(label)\n",
    "        cum_strengths = [np.maximum.accumulate(strength) for strength in all_strengths]\n",
    "        #all_strengths = all_strengths\n",
    "        mean_strengths = np.mean(all_strengths, axis=0)\n",
    "        lower_bound = np.percentile(cum_strengths, 10, axis=0)\n",
    "        indices = [0,1,2,3,4,5,6,7,8,9]\n",
    "        sum_all_strengths = sum(sum(all_strengths))\n",
    "        all_strength_one_list = [x for xs in all_strengths for x in xs ]\n",
    "        avg_strength = sum_all_strengths / len(all_strength_one_list)\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            mean_value = mean_strengths[idx] if idx < len(mean_strengths) else np.nan\n",
    "            lower_bound_value = lower_bound[idx] if idx < len(lower_bound) else np.nan\n",
    "            mean_dict[list(mean_dict.keys())[i]].append(mean_value)\n",
    "            lower_bound_dict[list(lower_bound_dict.keys())[i]].append(lower_bound_value)\n",
    "        \n",
    "        # mean_bias = np.mean(np.mean(all_strengths, axis=0))\n",
    "        # mean_lower_bound_bias = np.mean(np.percentile(all_strengths, 10, axis=0))\n",
    "        # mean_dict[list(mean_dict.keys())[10]].append(mean_bias)\n",
    "        # lower_bound_dict[list(lower_bound_dict.keys())[10]].append(mean_lower_bound_bias)\n",
    "        \n",
    "        mean_variance = np.std(np.mean(all_strengths, axis=0))\n",
    "        mean_lower_bound_variance = np.std(np.percentile(all_strengths, 10, axis=0))\n",
    "        mean_dict[list(mean_dict.keys())[10]].append(mean_variance)\n",
    "        mean_dict[list(mean_dict.keys())[11]].append(avg_strength)\n",
    "        lower_bound_dict[list(lower_bound_dict.keys())[10]].append(mean_lower_bound_variance)\n",
    "\n",
    "    df_mean = pd.DataFrame(mean_dict, index=configs).applymap(lambda x: round(x, 2))\n",
    "    df_lower_bound = pd.DataFrame(lower_bound_dict, index=configs).applymap(lambda x: round(x, 2))\n",
    "\n",
    "    print(\"Mean values:\")\n",
    "    display(df_mean.style.format(\"{:.1f}\").apply(highlight_max).apply(highlight_second).apply(highlight_third))\n",
    "    print(\"Lower bound values:\")\n",
    "    display(df_lower_bound.style.format(\"{:.1f}\").apply(highlight_max).apply(highlight_second).apply(highlight_third))\n",
    " \n",
    "    df_mean.to_csv(os.path.join('../results/', 'mean_values.csv'), sep=';', decimal=',', index=True)\n",
    "    df_lower_bound.to_csv(os.path.join('../results/', 'lower_bound_values.csv'), sep=';', decimal=',', index=True)\n",
    "\n",
    "# Create a button for showing the table\n",
    "show_button = widgets.Button(description='Show Table')\n",
    "\n",
    "def load_selected_data(btn):\n",
    "    \n",
    "    data = collections.defaultdict(list)\n",
    "    chain_reverse_mapping = {'Zero-Shot': '1', 'TT=3': '3','TT=5': '4','No Feedback': '5' }  # Reverse mapping textual representations to numeric strings\n",
    "\n",
    "    for selected in combo_widget.value:\n",
    "        split_selected = selected.split(\", \")\n",
    "\n",
    "        # For regular models\n",
    "        if len(split_selected) == 5 and \"Prompt\" in selected:  # Make sure there are 5 elements\n",
    "            selected_model = split_selected[0].split(\": \")[1]\n",
    "            selected_prompt = split_selected[1].split(\": \")[1]\n",
    "            selected_temp = split_selected[2].split(\": \")[1]\n",
    "            selected_target = split_selected[3].split(\": \")[1]\n",
    "            selected_chain_text = re.split(r\":\\s*\", split_selected[4].strip())[1]\n",
    "            selected_chain_numeric = chain_reverse_mapping.get(selected_chain_text, selected_chain_text)  # Map the text to its numeric representation\n",
    "            \n",
    "            \n",
    "            for filename in os.listdir('../results/LLM'):\n",
    "                info = extract_info(filename)\n",
    "                if info and info[:-2] == (selected_model, selected_prompt, selected_temp, selected_target) and str(info[-1]) == selected_chain_numeric:\n",
    "                    strength = load_data(os.path.join('../results/LLM', filename), info[-2])  # Use the budget\n",
    "                    data[(selected_model, selected_prompt, selected_temp, selected_target, selected_chain_text)].append(strength)\n",
    "                    # If the condition for TT=3 or TT=5 is met, adjust the strength data\n",
    "                    if selected_chain_text in ['TT=3', 'TT=5']:\n",
    "                        # Ensure the length is at least 14 to safely drop first 4 samples\n",
    "                        if len(strength) >= 14:\n",
    "                            strength = strength[4:14]  # Adjust to keep the 10 relevant samples\n",
    "\n",
    "        # For baseline models\n",
    "        elif len(split_selected) == 4 and \"Initial Samples\" in selected:\n",
    "            selected_model, selected_init_samples, selected_target, selected_budget = split_selected\n",
    "            selected_model = selected_model.split(\": \")[1]\n",
    "            selected_init_samples = selected_init_samples.split(\": \")[1]\n",
    "            selected_target = selected_target.split(\": \")[1]\n",
    "            selected_budget = selected_budget.split(\": \")[1]\n",
    "            if selected_model == 'BO':\n",
    "                for directory in ['../results/BO']:\n",
    "                    for filename in os.listdir(directory):\n",
    "                        try:\n",
    "                            info = extract_info_baseline(filename)\n",
    "                            strength = load_data_baseline(os.path.join(directory, filename), info[-1])\n",
    "                            data[info[:-1]].append(strength)\n",
    "                        except:\n",
    "                            pass\n",
    "            elif selected_model =='RF':\n",
    "                for directory in ['../results/RF']:\n",
    "                    for filename in os.listdir(directory):\n",
    "                        try:\n",
    "                            info = extract_info_baseline(filename)\n",
    "                            strength = load_data_baseline(os.path.join(directory, filename), info[-1])\n",
    "                            data[info[:-1]].append(strength)\n",
    "                        except:\n",
    "                            pass\n",
    "            elif selected_model =='RP':\n",
    "                for directory in ['../results/RP']:\n",
    "                    for filename in os.listdir(directory):\n",
    "                        try:\n",
    "                            info = extract_info_baseline(filename)\n",
    "                            strength = load_data_baseline(os.path.join(directory, filename), info[-1])\n",
    "                            data[info[:-1]].append(strength)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "\n",
    "    return data\n",
    "def on_show_table(btn):\n",
    "    # Acquire the lock\n",
    "    if not lock.acquire(blocking=False):\n",
    "        print('Another session is running, please wait...')\n",
    "        return\n",
    "\n",
    "    # Clear previous tables from the Output widget\n",
    "    table_output.clear_output(wait=True)\n",
    "    \n",
    "    data = load_selected_data(btn)  # we assume that this function loads the selected data\n",
    "\n",
    "    # Draw the new table inside the Output widget\n",
    "    with table_output:\n",
    "        # data = load_selected_data(btn)\n",
    "        # print(data)\n",
    "        show_table(data)\n",
    "\n",
    "    # # Release the lock\n",
    "    lock.release()\n",
    "\n",
    "show_button.on_click(on_show_table)\n",
    "\n",
    "table_output = widgets.Output()\n",
    "\n",
    "display(combo_widget, load_button,load_mean_button, plot_output, show_button, table_output);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
