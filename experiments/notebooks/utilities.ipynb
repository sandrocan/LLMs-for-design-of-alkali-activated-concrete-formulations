{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea772d5-c043-41e7-8ed0-6313d1b4bff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea711e09-2561-4f5b-b987-75cabb7cf78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.902499999999996\n"
     ]
    }
   ],
   "source": [
    "def check_strength(training_data, desired_strength):\n",
    "    # Check if any strength in the selected data is >= desired_strength\n",
    "    return any(s['strength'] >= desired_strength for s in training_data)\n",
    "\n",
    "def select_and_format_data(data, desired_strength):\n",
    "    while True:\n",
    "        # Randomly select 4 data points\n",
    "        selected_data = data.sample(n=4)  # Removed random_state for true randomness\n",
    "\n",
    "        # Parse selected data into the required format\n",
    "        training_data_formatted = []\n",
    "        tested_formulations = []\n",
    "        for _, row in selected_data.iterrows():\n",
    "            # Ensure these column names match your DataFrame exactly\n",
    "            powder = row[\"Powderkg\"]\n",
    "            wc = row[\"WC\"]\n",
    "            materials = row[\"Materials\"]\n",
    "            # Extract Fly Ash/GGBFS ratio and curing method from materials as done previously\n",
    "            fa_ggbfs = materials.split(\",\")[0].split(\"-\")[1]\n",
    "            curing_method = materials.split(\",\")[-1].strip()\n",
    "            curing_method = curing_method.replace(\" (Rao et al. 2018)\", \"\").replace(\" (Rao et al.)\", \"\")\n",
    "            strength = row[\"fc_28dGroundTruth\"]\n",
    "            \n",
    "            training_str = f\"Powderkg = {powder}, wc = {wc}, materials = {fa_ggbfs}, curing = {curing_method} resulted in a strength of {strength} MPa.\"\n",
    "            training_data_formatted.append({'formatted_str': training_str, 'strength': strength})\n",
    "            tested_str = f\"Powderkg = {powder}, wc = {wc}, materials = {fa_ggbfs}, curing = {curing_method}\"\n",
    "            tested_formulations.append(tested_str) \n",
    "\n",
    "        # Check if any selected data point's strength >= desired_strength\n",
    "        if not check_strength(training_data_formatted, desired_strength):\n",
    "            # Return both the formatted training data and the tested formulations\n",
    "            return [d['formatted_str'] for d in training_data_formatted], tested_formulations\n",
    "        \n",
    "def find_matching_result(df, suggestion):\n",
    "    if suggestion:\n",
    "        # Create the suggestion string in the same format as the formulation strings\n",
    "        suggestion_str = f'The formulation is Powderkg = {suggestion[\"powderkg\"]}, wc = {suggestion[\"wc\"]}, materials = {suggestion[\"materials\"]}, curing = {suggestion[\"curing\"]}'\n",
    "        TrainingDat = f'Powderkg = {suggestion[\"powderkg\"]}, wc = {suggestion[\"wc\"]}, materials = {suggestion[\"materials\"]}, curing = {suggestion[\"curing\"]}'\n",
    "        \n",
    "        # Look for a match in the DataFrame\n",
    "        match = df[df[\"Formulation\"].str.lower() == suggestion_str.lower()]\n",
    "        \n",
    "        # If a match was found, return the lab result and TrainingDat\n",
    "        if not match.empty:\n",
    "            return match.iloc[0][\"Strength\"], TrainingDat\n",
    "        \n",
    "        # If no match was found, print the suggestion string for debugging\n",
    "        else:\n",
    "            print(\"No match found for suggestion string: \", suggestion_str)\n",
    "\n",
    "    # If no suggestion provided or no match found, return None\n",
    "    return None, None\n",
    "\n",
    "def parse_solution(response):\n",
    "    # Initialize a dictionary to hold the solution\n",
    "    solution = {}\n",
    "\n",
    "    # Function to normalize key names\n",
    "    def normalize_key(key):\n",
    "        # Normalize common variations to a standard form\n",
    "        key_map = {\n",
    "            'powderkg': 'powderkg',\n",
    "            'wc': 'wc',\n",
    "            'materials': 'materials',\n",
    "            'curing': 'curing'\n",
    "        }\n",
    "        for known_key, normalized_key in key_map.items():\n",
    "            if known_key in key.lower().replace(\" \", \"\"):\n",
    "                return normalized_key\n",
    "        return None\n",
    "\n",
    "    # Try to parse the response as JSON\n",
    "    try:\n",
    "        json_data = json.loads(response)\n",
    "        for key, value in json_data.items():\n",
    "            normalized_key = normalize_key(key)\n",
    "            if normalized_key:\n",
    "                solution[normalized_key] = str(value)\n",
    "        if solution:  # If we successfully extracted data\n",
    "            return solution\n",
    "    except json.JSONDecodeError:\n",
    "        # If JSON parsing fails, proceed with regex parsing for the plain text format\n",
    "        keys = ['powderkg', 'wc', 'materials', 'curing']  # Updated to include 'curing'\n",
    "        for key in keys:\n",
    "            if key != 'curing':  # For 'curing', we might need a different approach\n",
    "                match = re.search(fr\"{key} = (.*?)(,|$)\", response, re.IGNORECASE)\n",
    "                if match:\n",
    "                    value = match.group(1).strip()\n",
    "                    solution[key] = value\n",
    "                else:\n",
    "                    # If any key wasn't found using regex, return None\n",
    "                    return None\n",
    "            else:\n",
    "                # Handle 'curing' specifically based on the presence of keywords\n",
    "                if \"ambient\" in response.lower():\n",
    "                    solution[\"curing\"] = \"Ambient curing\"\n",
    "                elif \"heat\" in response.lower():\n",
    "                    solution[\"curing\"] = \"Heat curing\"\n",
    "                else:\n",
    "                    # If 'curing' condition is not met, return None\n",
    "                    return None\n",
    "        return solution  # Return the solution dictionary if all keys were found with regex\n",
    "\n",
    "    # Return None if neither JSON nor regex parsing succeeded\n",
    "    return None\n",
    "\n",
    "    \n",
    "def format_response_to_model(lab_result):\n",
    "    \"\"\"\n",
    "    Given a lab result, format a response message to the model.\n",
    "    \"\"\"\n",
    "    return f\"We've achieved a compressive strength of {lab_result['fc_28d_Lab_validation']} MPa. Let's try to do better!\"\n",
    "\n",
    "def parse_materials(materials_str):\n",
    "    match = re.search(r'(\\d+)/(\\d+) FA/GGBFS', materials_str)\n",
    "    if match:\n",
    "        return int(match.group(1)) / (int(match.group(1)) + int(match.group(2)))\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def parse_curing(materials_str):\n",
    "    if \"Ambient curing\" in materials_str:\n",
    "        return \"ambient\"\n",
    "    elif \"Heat curing\" in materials_str:\n",
    "        return \"oven\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['FA_GGBFS_ratio'] = df['Materials'].apply(parse_materials)\n",
    "    df['curing'] = df['Materials'].apply(parse_curing)  # Add this line\n",
    "    return df\n",
    "\n",
    "def extract_formulations_from_training_data(training_data):\n",
    "    pattern = re.compile(r'Powderkg\\s*=\\s*(\\d+),\\s*wc\\s*=\\s*(\\d+\\.\\d+),\\s*materials\\s*=\\s*(\\d+\\.\\d+/\\d+\\.\\d+),\\s*curing\\s*=\\s*(\\w+)', re.IGNORECASE)\n",
    "    training_formulations = [match.group(0) for data in training_data for match in [pattern.search(data)] if match]\n",
    "    return training_formulations\n",
    "\n",
    "def handle_openai_error(exception):\n",
    "    if isinstance(exception, openai.error.RateLimitError):\n",
    "        print(f\"Rate limit error. Will retry after {exception.wait_seconds} seconds.\")\n",
    "        time.sleep(exception.wait_seconds)\n",
    "    elif isinstance(exception, openai.error.InvalidRequestError):\n",
    "        print(f\"Invalid request: {str(exception)}\")\n",
    "    elif isinstance(exception, openai.error.AuthenticationError):\n",
    "        print(f\"Authentication error: {str(exception)}\")\n",
    "    elif isinstance(exception, openai.error.ServiceUnavailableError):\n",
    "        print(f\"Service unavailable error. Retrying after a delay...\")\n",
    "        time.sleep(5)  # Sleep for 5 seconds before retrying\n",
    "    elif isinstance(exception, openai.error.APIError):\n",
    "        print(f\"API error: {str(exception)}. Retrying after a delay...\")\n",
    "        time.sleep(5)  # Sleep for 5 seconds before retrying\n",
    "    elif isinstance(exception, openai.error.Timeout):\n",
    "        print(f\"Timeout error: {str(exception)}. Retrying after a longer delay...\")\n",
    "        time.sleep(10)  # Sleep for 10 seconds before retrying\n",
    "    else:\n",
    "        raise exception\n",
    "        \n",
    "# -> here we also set the API parameters, such as temperature, etc.\n",
    "\n",
    "def call_openai_api(messages,temp, max_retries=5, delay=5):\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model= casperhansen/mixtral-instruct-awq,\n",
    "                temperature=temp,\n",
    "                messages=messages,\n",
    "                max_tokens=500,\n",
    "                n=1\n",
    "            )\n",
    "            return response\n",
    "        except openai.error.OpenAIError as e:\n",
    "            \n",
    "            handle_openai_error(e)\n",
    "            if i < max_retries - 1:  # i is zero indexed\n",
    "                time.sleep(delay)  # wait before trying again\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "pd.options.display.max_colwidth = 200\n",
    "def format_discovery_data_for_training():\n",
    "    df = load_data('../data/DiscoveryData_Sample.csv')\n",
    "    \n",
    "    # Initialize empty DataFrame\n",
    "    formulation_df = pd.DataFrame([],columns=[\"Formulation\", \"Strength\"])\n",
    "    \n",
    "    # Loop through each row in the original data\n",
    "    for idx, row in df.iterrows():\n",
    "        \n",
    "        # Get necessary attributes from row\n",
    "        powder = row[\"Powderkg\"]\n",
    "        wc = row[\"WC\"]\n",
    "        materials = row[\"Materials\"]\n",
    "    \n",
    "        # Extract Fly Ash/GGBFS ratio\n",
    "        fa_ggbfs = materials.split(\",\")[0].split(\"-\")[1]\n",
    "        \n",
    "        # Extract curing method\n",
    "        curing_method = materials.split(\",\")[-1].strip()\n",
    "    \n",
    "        # Remove unwanted string from curing method\n",
    "        curing_method = curing_method.replace(\" (Rao et al. 2018)\", \"\")\n",
    "        curing_method = curing_method.replace(\" (Rao et al.)\", \"\")\n",
    "        \n",
    "        # Compressive strength\n",
    "        strength = row[\"fc_28dGroundTruth\"]\n",
    "        \n",
    "        # Create formulation string in the same format as the model's output\n",
    "        formulation = f'The formulation is Powderkg = {powder}, wc = {wc}, materials = {fa_ggbfs}, curing = {curing_method}'\n",
    "        \n",
    "        # Append the formulation and its respective strength to the new DataFrame\n",
    "        new_row = pd.DataFrame({\"Formulation\": [formulation], \"Strength\": [strength]})\n",
    "        \n",
    "        formulation_df = pd.concat([formulation_df if not formulation_df.empty else None, new_row], ignore_index=True)\n",
    "    return formulation_df\n",
    "\n",
    "def calculate_quantiles_of_data():\n",
    "   df = pd.read_csv('../data/DiscoveryData_Sample.csv') \n",
    "   strength = df['fc_28dGroundTruth']\n",
    "   strength_quantile = strength.quantile(q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a817a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
