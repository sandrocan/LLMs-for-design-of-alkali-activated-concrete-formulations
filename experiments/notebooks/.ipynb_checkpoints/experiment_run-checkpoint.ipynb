{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "967760d5-3216-4592-be63-202dadd64124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b124e8-9a50-4098-ac1a-eee6fe8b6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utilities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "494cffd3-b979-46b2-87da-a78865c9cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_model_over_api(modelname, messages):\n",
    "\n",
    "    client = OpenAI(api_key = \"EMPTY\", base_url = \"http://mlserver.iteratec.de:8000/v1\")\n",
    "\n",
    "    chat_completion = '' \n",
    "    try: \n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model = modelname,\n",
    "            messages = messages\n",
    "        )\n",
    "\n",
    "    except openai.APIConnectionError as e:\n",
    "        print(\"The server could not be reached\")\n",
    "        print(e.__cause__)  # an underlying Exception, likely raised within httpx.\n",
    "    except openai.RateLimitError as e:\n",
    "        print(\"A 429 status code was received; we should back off a bit.\")\n",
    "    except openai.APIStatusError as e:\n",
    "        print(\"Another non-200-range status code was received\")\n",
    "        print(e.status_code)\n",
    "        print(e.response)\n",
    "    except openai.BadRequestError as e:\n",
    "        print(e.response)\n",
    "    except openai.InternalServerError as e:\n",
    "        print(e.response)\n",
    "    except openai.UnprocessableEntityError as e:\n",
    "        print(e.reponse)\n",
    "    except openai.NotFoundError as e:\n",
    "        print(e.response)\n",
    "    except openai.PermissionDeniedError as e:\n",
    "        print(e.response)\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "# prompt_model_over_api(\"casperhansen/mixtral-instruct-awq\", [{\"role\": \"user\", \"content\": 'system_message'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecf5ef3d-e0e3-434a-ad01-03327f681cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results():\n",
    "    timestamp = str(int(time.time()))\n",
    "\n",
    "    # create the file name\n",
    "    if 'None' in prompt_dropdown.value:\n",
    "        prompt_value = 'NoContext'\n",
    "    else:\n",
    "        prompt_value = 'SpecificContext'\n",
    "\n",
    "    if minimal_target_value_input.value:\n",
    "        target = f'min_target_strength_{minimal_target_value_input.value}'\n",
    "    else:\n",
    "        target = 'min_target_strength_not_specified'\n",
    "\n",
    "    if model_dropdown.value == 'casperhansen/mixtral-instruct-awq':\n",
    "        model_value = 'mixtral-instruct-awq'\n",
    "    else:\n",
    "        model_value = model_dropdown.value\n",
    "\n",
    "    filename = f\"../results/LLM/{model_value}_{prompt_value}_prompt_experiment_{experiment+1}_{target}_Dev_Cycles_{number_development_input.value}_test_time_{test_time_dropdown.value}_{timestamp}_{prompt_dropdown.value}.csv\"\n",
    "       \n",
    "        # open the file in write mode\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # write the headers\n",
    "        writer.writerow([\"Formulation\", \"Compressive Strength\"])\n",
    "\n",
    "        # iterate over the training data\n",
    "        for data in training_data:\n",
    "            try:\n",
    "                # parse the data to extract formulation and compressive strength\n",
    "                formulation, strength_str = data.split(\" resulted in a strength of \")\n",
    "                strength = float(strength_str.split(\" \")[0])  # convert string to float\n",
    "                writer.writerow([formulation, strength])\n",
    "            except ValueError as e:\n",
    "                print(f\"Failed to parse data: {data}\")\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "        print(f\"Data for experiment {experiment+1} successfully saved to {filename}. \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87aa7b10-bbab-4315-9e7a-9eb61d31a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_model_with_extended_test_time(modelname, training_data, messages):\n",
    "    predictions = []\n",
    "    unique_formulations = []\n",
    "\n",
    "    training_formulations = extract_formulations_from_training_data(training_data)\n",
    "    \n",
    "    # Add the new user prompt to ask for three unique formulations, if no previous conversation history, last message is from and just appending another user message causes api error\n",
    "    # If last message from user, append additional message to content else append entirely new message\n",
    "    if messages[-1][\"role\"] == \"user\":     \n",
    "        messages[-1][\"content\"] += (\"\\n Output 3 three completly new and untested formulations with a extremly high expected compressive strength , each of the three must adhere to the given structure and parameter limits!.\")\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": \"Output 3 three completly new and untested formulations with a extremly high expected compressive strength , each of the three must adhere to the given structure and parameter limits!.\"})\n",
    "              \n",
    "    # Make API call\n",
    "    model_response = prompt_model_over_api(model_dropdown.value, messages)\n",
    "\n",
    "    # # Extract the three formulations\n",
    "    response_lines = model_response.split('\\n')\n",
    "    # for line in response_lines:\n",
    "    #     print(line)\n",
    "    # Define a regular expression pattern to capture the relevant information\n",
    "    pattern = re.compile(r'Powderkg\\s*=\\s*(\\d+),\\s*wc\\s*=\\s*(\\d+\\.\\d+),\\s*materials\\s*=\\s*(\\d+\\.\\d+/\\d+\\.\\d+),\\s*curing\\s*=\\s*(\\w+)', re.IGNORECASE)\n",
    "\n",
    "    # # Use list comprehension to find all matches in the response lines\n",
    "    for line in response_lines:\n",
    "        match = pattern.search(line)\n",
    "        if match:\n",
    "            print(\"Found a match:\", match.group())\n",
    "        else:\n",
    "            print(\"No match found in:\", line)\n",
    "    \n",
    "    #formulations = [line for line in response_lines if line.startswith(\"The formulation is\")]\n",
    "    # if training_data:\n",
    "    #         unique_formulations = [f for f in formulations if f not in training_formulations]\n",
    "    #         if len(unique_formulations) == 0:\n",
    "    #             print('no new formulations extracted')\n",
    "    #         formulations = unique_formulations        \n",
    "    # Handle the case where all suggested formulations are duplicates\n",
    "    # Maybe prompt the assistant again or take other actions\n",
    "    # if training_data:\n",
    "    #     unique_formulations = [f for f in formulations if f not in training_formulations]\n",
    "    #     if len(unique_formulations) == 0:\n",
    "    #         print('no new formulations extracted')\n",
    "    formulations = unique_formulations  \n",
    "    # Or keep it as formulations_as_strings if you proceed with string comparisons  \n",
    "        # Handle the case where all suggested formulations are duplicates\n",
    "        # Maybe prompt the assistant again or take other actions\n",
    "\n",
    "    # print(f'These are the three suggested formulation : \\n{formulations}')\n",
    "        # predictions.append('element')\n",
    "        # Prepare the forward task prompt\n",
    "        \n",
    "    #     if training_data == []:\n",
    "    #         forward_prompt_base = f\"{context_text} \\n {VM_role_text}\"\n",
    "    #     else:\n",
    "    #         forward_prompt_base = f\"{context_text} \\n ////Previous Formulation and Lab Validation:\" + \"\\n\".join(training_data) + f\"\\n{VM_role_text}\"\n",
    "\n",
    "    #     for formulation in formulations:\n",
    "    #         # Create the full forward task prompt\n",
    "    #         forward_prompt = f\"{forward_prompt_base}\\n Considering this context, what is the compressive strength of {formulation}? Answer in this exact format: {'your estimate'} MPa\"\n",
    "\n",
    "    #         if conversation_dropdown.value == 'Complete':\n",
    "    #             print(\"Forward Prompt:\", forward_prompt)\n",
    "\n",
    "    #         # Make the API call to get the forward task prediction\n",
    "    #         forward_response = call_openai_api([{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": forward_prompt}], 0)\n",
    "\n",
    "    #         # Extract the predicted strength from the model's response\n",
    "    #         try:\n",
    "    #             predicted_strength_str = forward_response.choices[0].message.content.split(' ')[-2]\n",
    "    #             predicted_strength_str_cleaned = predicted_strength_str.strip(\"' \") \n",
    "\n",
    "    #             # Now convert to float\n",
    "    #             predicted_strength = float(predicted_strength_str_cleaned)\n",
    "    #         except ValueError:\n",
    "    #             print(f\"Could not convert predicted strength for {formulation} to float. Skipping this formulation.\")\n",
    "    #             continue\n",
    "\n",
    "    #         if conversation_dropdown.value == 'Complete':\n",
    "    #             print(f\"Predicted Strength for {formulation}: {predicted_strength} MPa\")\n",
    "\n",
    "    #         # Append to the predictions list\n",
    "    #         predictions.append((formulation, predicted_strength))\n",
    "            \n",
    "    #     if predictions:\n",
    "    #         break  # Exit the loop if valid predictions are found\n",
    "    #     else:\n",
    "    #         print(f\"No valid results on attempt {retry_count + 1}. Retrying...\")\n",
    "    #         retry_count += 1\n",
    "\n",
    "    # # Handle case where predictions list is empty\n",
    "    # if not predictions:\n",
    "    #     print(\"No valid predictions were made. Defaulting to the first formulation.\")\n",
    "    #     return {'role': 'assistant', 'content': formulations[0] if formulations else 'Unable to make valid predictions.'}\n",
    "\n",
    "    # # Select the formulation with the highest predicted strength\n",
    "    # final_response, best_strength = max(predictions, key=lambda x: x[1])\n",
    "    # # Return an instance of AssistantResponse\n",
    "    # return AssistantResponse('assistant', final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2398e46b-f646-4cf1-8d10-3e5f8215fa20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'number_experiments_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# experiments = 1\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# dev_cycles = 2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# iterate_prompt = \"////We have to improve the design. Ensure that your forthcoming suggestion is distinctive and hasn't been validated previously!\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# formulation_df = format_discovery_data_for_training()\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experiment \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mnumber_experiments_input\u001b[49m\u001b[38;5;241m.\u001b[39mvalue):\n\u001b[1;32m     11\u001b[0m     training_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m     tested_formulations \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'number_experiments_input' is not defined"
     ]
    }
   ],
   "source": [
    "# experiments = 1\n",
    "# dev_cycles = 2\n",
    "\n",
    "\n",
    "# DA_role_prompt = '////You are an advanced model designed to predict the optimal concrete formulation for maximum compressive strength. Your predictions will undergo laboratory testing, providing real-world performance data to enhance your future recommendations. Ensure each formulation adheres to the following parameter grid //Powder content in kg: 360, 370, 380, 390, 400, 410, 420, 430, 440, 450 //Water-to-cement (WC) ratio: 0.45, 0.5, 0.55, 0.6 //Materials: Fly-Ash/GGBFS at ratios of 0.7/0.3, 0.6/0.4, 0.5/0.5 //Curing methods: Ambient curing/Heat curing ////Leverage design rules and laboratory validations to refine and improve your predictive capabilities. Responses must be formatted precisely as follows, without any additional details or context: \"The formulation is Powderkg = {your estimate}, wc = {your estimate}, materials = {your estimate}, curing = {your estimate}\"'\n",
    "# context_prompt = '////General Design Insights//// The compressive strength of FA/GGBFS-based geopolymer concrete improves with increased powder content due to enhanced particle packing and the pozzolanic reaction. Under ambient curing, the optimal powder content or \"sweet spot\" is approximately 400 kg, while under heat curing, it is closer to 420 kg/m³ due to the hastened geopolymerization process. //The W/C ratio in the range of 0.45 to 0.6 results in diminished compressive strength of FA/GGBFS-based geopolymer concrete, attributed to increased porosity. A \"sweet spot\" W/C ratio of around 0.5 is ideal under both ambient and heat curing conditions, providing a harmonious balance between workability and strength. //A lower FA/GGBFS ratio of 0.5/0.5 in blended materials leads to increased compressive strength due to a greater GGBFS content.// Adjust the FA/GGBS ratio first, since it plays a crucial role in compressive strength due to the combined effects of FA and GGBS. Altering the W/C ratio is essential as it affects porosity and consequently, strength. Lastly, optimizing powder content is imperative as it impacts particle packing and pozzolanic reaction.'\n",
    "# iterate_prompt = \"////We have to improve the design. Ensure that your forthcoming suggestion is distinctive and hasn't been validated previously!\"\n",
    "# formulation_df = format_discovery_data_for_training()\n",
    "\n",
    "for experiment in range(number_experiments_input.value):\n",
    "    training_data = []\n",
    "    tested_formulations = []\n",
    "    print(f'Starting experiment number {experiment+1} ...\\n')\n",
    "    system_message =  DA_role_prompt.value  + '\\n' + context_prompt.value\n",
    "    highest_strength = 0.0\n",
    "\n",
    "    for dev_cycle in range(number_development_input.value):\n",
    "        print(f'Development cycle : {dev_cycle+1} \\n\\n')\n",
    "        current_strength = 0.0\n",
    "        messages = [{\"role\": \"user\", \"content\": system_message}]\n",
    "\n",
    "        if training_data:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": \"Previously, we have tested these formulations:\\n\" + \"\\n\".join(tested_formulations)})\n",
    "                messages.append({\"role\": \"user\", \"content\": iterate_prompt.value})\n",
    "\n",
    "\n",
    "        valid_solution = False\n",
    "        while not valid_solution:\n",
    "            if test_time_dropdown.value == '3':\n",
    "                print('Using extended test time...')\n",
    "                model_response = prompt_model_with_extended_test_time(model_dropdown.value, training_data, messages)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                model_response = prompt_model_over_api(model_dropdown.value, messages)\n",
    "    \n",
    "            # print(\"--- Conversation History ---\")\n",
    "            # for msg in messages:\n",
    "            #     print(f\"{msg['role']}: {msg['content']} \\n\")\n",
    "    \n",
    "            # print(f'Current training data : {training_data}')\n",
    "            parsed_solution = parse_solution(model_response)\n",
    "\n",
    "            if parsed_solution is not None:\n",
    "                (lab_result, new_training_data_point) = find_matching_result(formulation_df, parsed_solution)\n",
    "                            \n",
    "                if lab_result:\n",
    "                    current_strength = lab_result\n",
    "                    if current_strength > highest_strength:\n",
    "                        highest_strength = current_strength\n",
    "                    print(f'Lab data discovered for the following formulation : {new_training_data_point}')\n",
    "                    training_data.append(f\"{new_training_data_point} resulted in a strength of {current_strength} MPa.\")\n",
    "                    tested_formulations.append(f\"{new_training_data_point}\")\n",
    "                                      \n",
    "                    valid_solution = True\n",
    "                                \n",
    "                    print(f'The suggested formulation achieved a strength of {current_strength} MPa. \\n\\n')\n",
    "                else:\n",
    "                    print(f\"Development cycle {dev_cycle}: No matching lab result found for suggestion {parsed_solution} \\n\\n\")\n",
    "            if not valid_solution:\n",
    "                print(f\"Development cycle {dev_cycle}: Model's response did not contain a valid solution. Trying again. \\n\\n\")\n",
    "                messages[-1][\"content\"] = iterate_prompt.value + \"\\nRemember the exact parameter grid: Powderkg: {360, 370, 380, 390,400, 410, 420, 430, 440, 450}, wc: {0.45, 0.5, 0.55, 0.6}, materials: {0.7/0.3, 0.6/0.4, 0.5/0.5}, curing: {ambient, heat}. It is extremly important that you stick to these values and reply in the following format: 'The formulation is Powderkg = {your estimate}, wc = {your estimate}, materials = {your estimate}, curing = {your estimate}'\"\n",
    "       \n",
    "        if current_strength >= minimal_target_value_input.value:\n",
    "            print(f\"\\nDesired compressive strength of {minimal_target_value_input.value} MPa achieved after {dev_cycle+1} iterations. The solution is {parsed_solution}. \\n\\n\")\n",
    "            break\n",
    "        \n",
    "    print(f'We have tested the following formulations : {tested_formulations} \\n\\n')\n",
    "    print(f'The highest strength out of the formulation we predicted is : {highest_strength} \\n\\n')\n",
    "\n",
    "    save_results()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
